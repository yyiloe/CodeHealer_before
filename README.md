# CodeHealer
## [CodeHealer]Context-based Transfer Learning for Structuring Fault Localization and Program Repair Automation
![The overview of CodeHealer to perform fault localization and automated program repair.\label{step}](./framework.png) 
**Requirements:**
1. **Java 1.7**
2. **Python 3.8**
3. **Defects4j 1.2.0**
4. **pytorch-1.11.0**
5. **cudatoolkit 11.3**
6. **SVN >= 1.8**
7. **Perl >= 5.0.10**
***
## Dataset:
You can click on the link below to obtain the necessary dataset for this research：
* [CodeHealer_dataset](https://github.com/yyiloe/CodeHealer)

Unzip this zip file, and you will get three files：`dataset_fl.pkl`,`dataset_pr.pkl`,`src_code.pkl`.
1. `dataset_fl.pkl`:train eleven binary classifiers based on the multi-head attention mechanism for the fault localization part.
2. `dataset_pr.pkl`:pretrain a multi-classifier based on the multi-head attention mechanism for the fault repair part.
3. `src_code.pkl`:target source code.

Place the three files in the corresponding paths as follows:
* Put `dataset_fl.pkl` into `./fault_localization/`
* Put `dataset_pr.pkl` into `./program_repair/`
* Put `src_code.pkl` into `./fault_localization/binary_classification/d4j_data/` 
***
## Replicate our experimental results:
CodeHealer consists of three main components: Deep Semantic Information Extraction, Suspicious Statement Ranking, and Fault Repair. The Deep semantic information extraction component employs a classifier based on a multi-head self-attention mechanism to effectively extract deep semantic features from suspicious code statements. The attention mechanism enables parallel processing of lengthy statements, capturing a more extensive range of dependencies while weakening temporal features. The suspicious statement ranking component combines various fault localization features, utilizing a multi-layer perceptron to obtain a vector of suspicious values for multi-dimensional features, thereby achieving optimal performance in fault localization.The fault repair component, based on the ranked suspicious statements generated by fault localization, adopts a top-down approach. It utilizes a multi-classifier based on a self-attention mechanism to select repair templates and generate patches,aiming to accurately fix more faults within a given timeframe. This method of optimizing the template selection process addresses the efficiency and accuracy issues associated with the traditional traversal method of template selection.
### Fault Localization:
1. enter `./fault_localization/binary_classification/script/` and run `python data_preprocess.py <fix_template>` to obtain the processed training datasets for each bug category.(<fix_template>:InsertMissedStmt、InsertNullPointerChecker、MoveStmt、MutateConditionalExpr、MutateDataType、MutateLiteralExpr、MutateMethodInvExpr、MutateOperators、MutateReturnStmt、MutateVariable、RemoveBuggyStmt)
2. enter ./fault_localization/binary_classification/code/ and run python train.py <fix_tempalte> to train the corresponding binary classifier.The model weights for each classifier are saved in folder `./model_save/`.
3. enter `./fault_localization/binary_classification/script/` and run `python data_preprocess_for_d4j.py <fix_remplate>` to preprocess each suspicious statement in defects4j dataset.
4. enter `./fault_localization/binary_classification/code/` and run `python predict_for_d4j.py` to obtain the final 11-dim semantic features which lotates in `../d4j_data/semantic.pkl`.
5. enter `./fault_localization/ranking_task/` and run `python gen_data.py` to generate samples from defects4J with 3 different feature groups.the spectrum-based and mutation-based features are already extracted by using [GZoltar 1.7.2](https://github.com/GZoltar/gzoltar/releases/tag/v1.7.2) and [PIT 1.1.5](https://pitest.org/downloads/) tools respectively. 
6. enter the path `./fault_localization/ranking_task/run_model/`, and run `python run_group.py` command.This command includes the process of dividing the training set into ten folds for cross-validation and conducting training and testing.

### Automated Program Repair:
* To conduct the fault repair experiments, you need to configure the Defects4J dataset first.
Download and install [Defects4J 1.2.0](https://github.com/rjust/defects4j/releases/tag/v1.2.0) ,and you need its README to complete all the configurations.
Check out and compile each bug. There are 395 bugs in total, but only 71 bugs are necessary to be checked out for our repair experiments, which are listed in`./program_repair/automatic_fix/versions.txt`. All checked out bugs should be put into the directory `./program_repair/automatic_fix/projects/` and follow the same naming standard with `versions.txt` (i.g., Chart_1).
Export environment variable `D4J_HOME` as the root dir of Defects4j.
1. enter `./program_repair/pattern_selection/` and run `python pipeline.py` to obtain the training data for the pre-trained multi-classifier based on the multi-head attention mechanism.The data includes pre-training data and the Defects4j data after being divided by ten-fold cross-validation.
2. enter the same dir, and run `python train_github.py` to train the multi-classifier.The pre-trained model weights after training are saved in folder `./model_save/`.
3. enter the same dir, and run `python train_d4j.py` to fine-tune the parameters of the model.The weights of all models after fine-tuning are saved in folder `./model_save_d4j/`.

The trained multi-classifier can be embeded into the state-of-the-art template-based program repair technique [TBar](https://github.com/TruX-DTF/TBar) to optimize the fix template selection task.
1. copy `./program_repair/pattern_selection/model_save_d4j/` and `./program_repair/pattern_selection/data/train/embedding/w2v_512` to `./program_repair/automatic_fix/dnn_model/`, and then run `python parse_version.py`.
2. enter `./program_repair/automatic_fix/script/` and run `python get_sus_file.py`.
3. enter the path `./program_repair/automatic_fix/shell_71_versions/`, and run `python generate_shell.py` to generate the shell file containing 71 serial commands for 71 bugs in Defects4J.
4. run `chomd +x run_repair.sh`to give the executable authority to the newly generated shell file.
5. run `./run_repair.sh` to obtain the repair result.All repair logs are shown in `./program_repair/dnn_model/dnn_tbar_log/`, and all generated plausible patches are shown in `./program_repair/automatic_fix/OUTPUT/`. 
* Note: We have provided fine-tuned weight files that can reproduce our repair results. If you want to quickly obtain experimental results, after configuring Defects4J, you can directly run 1, 3, 4, 5.










